---
layout:     post
title:      打开黑箱重要一步，MIT提出TbD-net，弥合视觉推理模型的性能与可解释性鸿沟
subtitle:   ""
date:       2018-03-17
author:     " "
header-img: "img/home-bg-o.jpg"
tags:
    - 新闻
---

本文主要内容：近日，MIT 林肯实验室和 Planck Aerosystems 联合发布论文，提出一组可组合的视觉推理原语，并构建了 Transparency by Design network（TbD-net），通过整合注意力机制推进了模型透明度，同时又保证了高性能。TbD 在 CLEVR 数据集上达到了当前最优的准确率 99.1%；在 CoGenT 泛化任务上，TbD 比当前最优的模型提升了超过 20 个百分点。该论文被贴到 reddit 上后立刻引起大量关注。机器之心对该研究进行了介绍。




<!-- more -->

## 主要内容

近日，MIT 林肯实验室和 Planck Aerosystems 联合发布论文，提出一组可组合的视觉推理原语，并构建了 Transparency by Design network（TbD-net），通过整合注意力机制推进了模型透明度，同时又保证了高性能。TbD 在 CLEVR 数据集上达到了当前最优的准确率 99.1%；在 CoGenT 泛化任务上，TbD 比当前最优的模型提升了超过 20 个百分点。该论文被贴到 reddit 上后立刻引起大量关注。机器之心对该研究进行了介绍。

GitHub 地址：https://github.com/davidmascharka/tbd-nets

视觉问答（VQA）模型必须能够对图像进行复杂的空间推理。例如，为了回答问题：「大金属球右侧的立方体是什么颜色？」这个问题，机器学习模型必须确定哪个球体是大个、金属材质的，必须理解右侧是什么样的位置概念，并将这些概念应用于视野内所有物体。在新的探索区域内，模型必须找到立方体，并识别它的颜色。该行为应该是组合的，并可以允许任意长度的推理链。

![images](/images\news\2018-3-17-heixiang.jpg)

尽管最近研究者针对 VQA 任务提出了大量不同的模型 [8, 12, 23, 26, 35, 37]，但神经模块网络 [2, 3, 12, 18] 是其中最直观的。神经模块网络由 Andreas et al. [2] 提出，由各自执行独立操作的一系列模块组成，以解决特定问题。它很好地建模了视觉推理任务的组合属性。早期研究中运用注意力机制设计模块，这种设计允许观察模型操作。但是，这一方法在复杂的视觉推理任务比如 CLEVR [17] 上表现并不好。Johnson et al. [18] 以损失模型透明度为代价解决了这一性能问题。但问题依然存在，因为要想确保适当的模型行为、取得用户信任、诊断推理误差，检查推理过程每一步的能力在实际应用中十分关键。

通过根据视觉注意力机制明确地设计一个模块网络，该论文的研究弥合了模型性能与可解释性之间的鸿沟。本论文作者把这一方法称为 Transparency by Design（TbD），如图 1 所示。Lipton [20] 指出，透明度和可解释性经常被提及，却从未被定义。本文将透明度定义为检查每个模块的中间输出、理解其高级行为的能力。也就是说，如果模块从视觉上强调了输入图像的正确区域，则模块输出是可解释的。这确保了推理过程的可解释性。章节 4.1 中具体定义了这一概念，并提供了量化分析。在本文中，研究者：


- 提出一组可组合的视觉推理原语，其整合了注意力机制，推进了模型透明度；
- 在 CLEVR [17] 数据集上展示了当前最优的性能；
- 表明组合性视觉注意力可以清晰洞察模型行为；
- 提出一种可以量化评估视觉注意力机制可解释性的方法；
- 在 CoGenT 泛化任务中 [17]，把当前最优性能提升了 20 个百分点。

[文章未完，点击这里查看全文（来自机器之心）](http://mp.weixin.qq.com/s/210l9K94KMqtJtqbrZ-mgg)